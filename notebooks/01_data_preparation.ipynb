{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f858c4a8-bf6d-44b1-b9d6-87c274e1c336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames loaded successfully. Head of each:\n",
      "\n",
      "Per 100 Possessions:\n",
      "  Rk           Player   Age Team Pos     G    GS      MP    FG   FGA  ...  \\\n",
      "0  1    Mikal Bridges  28.0  NYK  SF  82.0  82.0  3036.0   9.7  19.3  ...   \n",
      "1  2        Josh Hart  29.0  NYK  SG  77.0  77.0  2897.0   6.9  13.2  ...   \n",
      "2  3  Anthony Edwards  23.0  MIN  SG  79.0  79.0  2871.0  12.4  27.7  ...   \n",
      "3  4     Devin Booker  28.0  PHO  SG  75.0  75.0  2795.0  11.6  25.1  ...   \n",
      "4  5     James Harden  35.0  LAC  PG  79.0  79.0  2789.0   9.4  22.9  ...   \n",
      "\n",
      "    AST  STL  BLK  TOV   PF   PTS   ORtg   DRtg  Awards  Player-additional\\  \n",
      "0   5.0  1.2  0.7  2.2  2.1  23.6  117.0  118.0     NaN          bridgmi01\\  \n",
      "1   7.8  2.0  0.5  2.7  3.4  18.0  125.0  112.0     NaN           hartjo01\\  \n",
      "2   6.2  1.6  0.9  4.3  2.6  37.4  115.0  112.0  ASNBA2          edwaran01\\  \n",
      "3   9.4  1.2  0.3  3.9  3.5  34.0  119.0  123.0     NaN          bookede01\\  \n",
      "4  12.1  2.1  1.0  6.0  2.9  31.8  114.0  110.0  ASNBA3          hardeja01\\  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "Advanced Stats:\n",
      "  Rk           Player   Age Team Pos     G    GS      MP   PER    TS%  ...  \\\n",
      "0  1    Mikal Bridges  28.0  NYK  SF  82.0  82.0  3036.0  14.0  0.585  ...   \n",
      "1  2        Josh Hart  29.0  NYK  SG  77.0  77.0  2897.0  16.5  0.611  ...   \n",
      "2  3  Anthony Edwards  23.0  MIN  SG  79.0  79.0  2871.0  20.1  0.595  ...   \n",
      "3  4     Devin Booker  28.0  PHO  SG  75.0  75.0  2795.0  19.3  0.589  ...   \n",
      "4  5     James Harden  35.0  LAC  PG  79.0  79.0  2789.0  20.0  0.582  ...   \n",
      "\n",
      "   OWS  DWS   WS  WS/48  OBPM  DBPM  BPM  VORP  Awards  Player-additional\\  \n",
      "0  3.7  2.0  5.7  0.090   0.4  -0.9 -0.5   1.2     NaN          bridgmi01\\  \n",
      "1  5.4  3.8  9.2  0.153   1.1   1.8  2.8   3.6     NaN           hartjo01\\  \n",
      "2  4.6  3.8  8.4  0.140   4.4   0.0  4.3   4.6  ASNBA2          edwaran01\\  \n",
      "3  6.1  0.3  6.4  0.111   2.8  -2.4  0.4   1.7     NaN          bookede01\\  \n",
      "4  4.0  4.3  8.3  0.143   3.5   0.8  4.3   4.4  ASNBA3          hardeja01\\  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Shooting Stats:\n",
      "  Rk           Player   Age Team Pos     G    GS      MP    FG%  Dist.  ...  \\\n",
      "0  1    Mikal Bridges  28.0  NYK  SF  82.0  82.0  3036.0  0.500   14.7  ...   \n",
      "1  2        Josh Hart  29.0  NYK  SG  77.0  77.0  2897.0  0.525   11.3  ...   \n",
      "2  3  Anthony Edwards  23.0  MIN  SG  79.0  79.0  2871.0  0.447   16.9  ...   \n",
      "3  4     Devin Booker  28.0  PHO  SG  75.0  75.0  2795.0  0.461   16.2  ...   \n",
      "4  5     James Harden  35.0  LAC  PG  79.0  79.0  2789.0  0.410   17.3  ...   \n",
      "\n",
      "   %FG AST 2P  %FG AST 3P  %FGA Dunks  # of Dunks  Coner %3PA  Corner 3P%  \\\n",
      "0       0.682       0.957       0.025        28.0       0.449       0.423   \n",
      "1       0.613       0.869       0.030        21.0       0.258       0.308   \n",
      "2       0.384       0.475       0.039        54.0       0.107       0.414   \n",
      "3       0.431       0.716       0.013        14.0       0.123       0.338   \n",
      "4       0.176       0.370       0.003         4.0       0.042       0.429   \n",
      "\n",
      "   Heaves Att.  Heaves Md.  Awards      -9999\\  \n",
      "0         12.0         0.0     NaN  bridgmi01\\  \n",
      "1          1.0         0.0     NaN   hartjo01\\  \n",
      "2         10.0         0.0  ASNBA2  edwaran01\\  \n",
      "3          0.0         0.0     NaN  bookede01\\  \n",
      "4          0.0         0.0  ASNBA3  hardeja01\\  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "=== COLUMN NAMES ===\n",
      "Per 100 Possessions columns:\n",
      "['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'ORtg', 'DRtg', 'Awards', 'Player-additional\\\\']\n",
      "\n",
      "Advanced Stats columns:\n",
      "['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards', 'Player-additional\\\\']\n",
      "\n",
      "Shooting Stats columns:\n",
      "['Rk', 'Player', 'Age', 'Team', 'Pos', 'G', 'GS', 'MP', 'FG%', 'Dist.', '%FGA 2P', '%FGA 0-3', '%FGA 3-10', '%FGA 10-16', '%FGA 16-3P', '%FGA 3P', 'FG% 2P', 'FG% 0-3', 'FG% 3-10', 'FG% 10-16', 'FG% 16-3P', 'FG% 3P', '%FG AST 2P', '%FG AST 3P', '%FGA Dunks', '# of Dunks', 'Coner %3PA', 'Corner 3P%', 'Heaves Att.', 'Heaves Md.', 'Awards', '-9999\\\\']\n",
      "\n",
      "Checking column 'Player':\n",
      "  Per 100 Possessions: ✓\n",
      "  Advanced Stats: ✓\n",
      "  Shooting Stats: ✓\n",
      "\n",
      "Checking column 'Team':\n",
      "  Per 100 Possessions: ✓\n",
      "  Advanced Stats: ✓\n",
      "  Shooting Stats: ✓\n",
      "\n",
      "Checking column 'Age':\n",
      "  Per 100 Possessions: ✓\n",
      "  Advanced Stats: ✓\n",
      "  Shooting Stats: ✓\n",
      "\n",
      "✓ Age columns converted to float\n",
      "✓ Player columns converted to string\n",
      "✓ Team columns converted to string\n",
      "\n",
      "=== DATA TYPES BEFORE MERGING ===\n",
      "Per 100 Possessions - Age: float64\n",
      "Advanced Stats - Age: float64\n",
      "Shooting Stats - Age: float64\n",
      "\n",
      "✓ First merge completed successfully\n",
      "✓ Second merge completed successfully\n",
      "\n",
      "--- Merged DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 737 entries, 0 to 736\n",
      "Data columns (total 90 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Rk_per100                  736 non-null    object \n",
      " 1   Player                     737 non-null    object \n",
      " 2   Age                        735 non-null    float64\n",
      " 3   Team                       737 non-null    object \n",
      " 4   Pos_per100                 735 non-null    object \n",
      " 5   G_per100                   735 non-null    float64\n",
      " 6   GS_per100                  735 non-null    float64\n",
      " 7   MP_per100                  735 non-null    float64\n",
      " 8   FG                         735 non-null    float64\n",
      " 9   FGA                        735 non-null    float64\n",
      " 10  FG%                        732 non-null    float64\n",
      " 11  3P                         735 non-null    float64\n",
      " 12  3PA                        735 non-null    float64\n",
      " 13  3P%                        691 non-null    float64\n",
      " 14  2P                         735 non-null    float64\n",
      " 15  2PA                        735 non-null    float64\n",
      " 16  2P%                        725 non-null    float64\n",
      " 17  eFG%                       732 non-null    float64\n",
      " 18  FT                         735 non-null    float64\n",
      " 19  FTA                        735 non-null    float64\n",
      " 20  FT%                        694 non-null    float64\n",
      " 21  ORB                        735 non-null    float64\n",
      " 22  DRB                        735 non-null    float64\n",
      " 23  TRB                        735 non-null    float64\n",
      " 24  AST                        735 non-null    float64\n",
      " 25  STL                        735 non-null    float64\n",
      " 26  BLK                        735 non-null    float64\n",
      " 27  TOV                        735 non-null    float64\n",
      " 28  PF                         735 non-null    float64\n",
      " 29  PTS                        735 non-null    float64\n",
      " 30  ORtg                       735 non-null    float64\n",
      " 31  DRtg                       735 non-null    float64\n",
      " 32  Awards_per100              36 non-null     object \n",
      " 33  Player-additional\\_per100  736 non-null    object \n",
      " 34  Rk_adv                     736 non-null    object \n",
      " 35  Pos_adv                    735 non-null    object \n",
      " 36  G_adv                      735 non-null    float64\n",
      " 37  GS_adv                     735 non-null    float64\n",
      " 38  MP_adv                     735 non-null    float64\n",
      " 39  PER                        735 non-null    float64\n",
      " 40  TS%                        732 non-null    float64\n",
      " 41  3PAr                       732 non-null    float64\n",
      " 42  FTr                        732 non-null    float64\n",
      " 43  ORB%                       736 non-null    float64\n",
      " 44  DRB%                       736 non-null    float64\n",
      " 45  TRB%                       736 non-null    float64\n",
      " 46  AST%                       736 non-null    float64\n",
      " 47  STL%                       736 non-null    float64\n",
      " 48  BLK%                       736 non-null    float64\n",
      " 49  TOV%                       733 non-null    float64\n",
      " 50  USG%                       736 non-null    float64\n",
      " 51  OWS                        735 non-null    float64\n",
      " 52  DWS                        735 non-null    float64\n",
      " 53  WS                         735 non-null    float64\n",
      " 54  WS/48                      735 non-null    float64\n",
      " 55  OBPM                       735 non-null    float64\n",
      " 56  DBPM                       735 non-null    float64\n",
      " 57  BPM                        735 non-null    float64\n",
      " 58  VORP                       735 non-null    float64\n",
      " 59  Awards_adv                 36 non-null     object \n",
      " 60  Player-additional\\_adv     736 non-null    object \n",
      " 61  Rk                         736 non-null    object \n",
      " 62  Pos                        735 non-null    object \n",
      " 63  G                          735 non-null    float64\n",
      " 64  GS                         735 non-null    float64\n",
      " 65  MP                         735 non-null    float64\n",
      " 66  FG%_shooting               732 non-null    float64\n",
      " 67  Dist.                      732 non-null    float64\n",
      " 68  %FGA 2P                    732 non-null    float64\n",
      " 69  %FGA 0-3                   732 non-null    float64\n",
      " 70  %FGA 3-10                  732 non-null    float64\n",
      " 71  %FGA 10-16                 732 non-null    float64\n",
      " 72  %FGA 16-3P                 732 non-null    float64\n",
      " 73  %FGA 3P                    732 non-null    float64\n",
      " 74  FG% 2P                     725 non-null    float64\n",
      " 75  FG% 0-3                    706 non-null    float64\n",
      " 76  FG% 3-10                   704 non-null    float64\n",
      " 77  FG% 10-16                  653 non-null    float64\n",
      " 78  FG% 16-3P                  572 non-null    float64\n",
      " 79  FG% 3P                     691 non-null    float64\n",
      " 80  %FG AST 2P                 714 non-null    float64\n",
      " 81  %FG AST 3P                 635 non-null    float64\n",
      " 82  %FGA Dunks                 732 non-null    float64\n",
      " 83  # of Dunks                 735 non-null    float64\n",
      " 84  Coner %3PA                 691 non-null    float64\n",
      " 85  Corner 3P%                 653 non-null    float64\n",
      " 86  Heaves Att.                735 non-null    float64\n",
      " 87  Heaves Md.                 735 non-null    float64\n",
      " 88  Awards                     36 non-null     object \n",
      " 89  -9999\\                     736 non-null    object \n",
      "dtypes: float64(76), object(14)\n",
      "memory usage: 518.3+ KB\n",
      "None\n",
      "\n",
      "Final Merged DataFrame Head:\n",
      "  Rk_per100           Player   Age Team Pos_per100  G_per100  GS_per100  \\\n",
      "0         1    Mikal Bridges  28.0  NYK         SF      82.0       82.0   \n",
      "1         2        Josh Hart  29.0  NYK         SG      77.0       77.0   \n",
      "2         3  Anthony Edwards  23.0  MIN         SG      79.0       79.0   \n",
      "3         4     Devin Booker  28.0  PHO         SG      75.0       75.0   \n",
      "4         5     James Harden  35.0  LAC         PG      79.0       79.0   \n",
      "\n",
      "   MP_per100    FG   FGA  ...  %FG AST 2P  %FG AST 3P  %FGA Dunks  # of Dunks  \\\n",
      "0     3036.0   9.7  19.3  ...       0.682       0.957       0.025        28.0   \n",
      "1     2897.0   6.9  13.2  ...       0.613       0.869       0.030        21.0   \n",
      "2     2871.0  12.4  27.7  ...       0.384       0.475       0.039        54.0   \n",
      "3     2795.0  11.6  25.1  ...       0.431       0.716       0.013        14.0   \n",
      "4     2789.0   9.4  22.9  ...       0.176       0.370       0.003         4.0   \n",
      "\n",
      "   Coner %3PA  Corner 3P%  Heaves Att.  Heaves Md.  Awards      -9999\\  \n",
      "0       0.449       0.423         12.0         0.0     NaN  bridgmi01\\  \n",
      "1       0.258       0.308          1.0         0.0     NaN   hartjo01\\  \n",
      "2       0.107       0.414         10.0         0.0  ASNBA2  edwaran01\\  \n",
      "3       0.123       0.338          0.0         0.0     NaN  bookede01\\  \n",
      "4       0.042       0.429          0.0         0.0  ASNBA3  hardeja01\\  \n",
      "\n",
      "[5 rows x 90 columns]\n",
      "\n",
      "DataFrame shape after dropping redundant columns: (737, 85)\n",
      "Columns after dropping redundant ones:\n",
      "['Rk_per100', 'Player', 'Age', 'Team', 'Pos_per100', 'G_per100', 'GS_per100', 'MP_per100', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'ORtg', 'DRtg', 'Awards_per100', 'Player-additional\\\\_per100', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Awards_adv', 'Player-additional\\\\_adv', 'Rk', 'Pos', 'G', 'GS', 'MP', 'FG%_shooting', 'Dist.', '%FGA 2P', '%FGA 0-3', '%FGA 3-10', '%FGA 10-16', '%FGA 16-3P', '%FGA 3P', 'FG% 2P', 'FG% 0-3', 'FG% 3-10', 'FG% 10-16', 'FG% 16-3P', 'FG% 3P', '%FG AST 2P', '%FG AST 3P', '%FGA Dunks', '# of Dunks', 'Coner %3PA', 'Corner 3P%', 'Heaves Att.', 'Heaves Md.', 'Awards', '-9999\\\\']\n",
      "\n",
      "Filtered to players with >= 500 minutes. New shape: (436, 85)\n",
      "\n",
      "--- Missing Value Check (before imputation) ---\n",
      "3P%               10\n",
      "Awards_per100    400\n",
      "Awards_adv       400\n",
      "FG% 10-16          4\n",
      "FG% 16-3P         26\n",
      "FG% 3P            10\n",
      "%FG AST 3P        27\n",
      "Coner %3PA        10\n",
      "Corner 3P%        15\n",
      "Awards           400\n",
      "dtype: int64\n",
      "\n",
      "--- Missing Value Check (after imputation) ---\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Merged and cleaned data (unscaled) saved to ../data/processed/nba_2025_player_stats_merged_cleaned.csv\n",
      "\n",
      "Warning: The following desired features are missing and will be excluded from clustering: ['2P_FG%', '0-3_FG%', '3-10_FG%', '10-16_FG%', '16-3P_FG%']\n",
      "Please check your original CSVs and merge process if these are critical.\n",
      "\n",
      "DataFrame for clustering created with shape: (436, 30)\n",
      "Columns for clustering:\n",
      "['PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'PF', 'FG%', '3P%', '2P%', 'FT%', 'eFG%', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'BPM', 'VORP', 'Dist.']\n",
      "\n",
      "--- Scaled Features Head ---\n",
      "        PTS       AST       TRB       STL       BLK       TOV        PF  \\\n",
      "0  0.219874 -0.103204 -1.177485 -0.811858 -0.359945 -0.458698 -1.571965   \n",
      "1 -0.603001  0.944976  0.917143  0.589310 -0.614092 -0.001050 -0.423486   \n",
      "2  2.247671  0.346016 -0.304723 -0.111274 -0.105797  1.463427 -1.130242   \n",
      "3  1.748069  1.543936 -0.878252 -0.811858 -0.868239  1.097307 -0.335142   \n",
      "4  1.424797  2.554680 -0.204979  0.764456  0.021276  3.019432 -0.865209   \n",
      "\n",
      "        FG%       3P%       2P%  ...      BLK%      TOV%      USG%       OWS  \\\n",
      "0  0.465977  0.247549  0.831608  ... -0.396690 -0.691456  0.052407  1.143497   \n",
      "1  0.839114  0.040330  1.198810  ... -0.661859  0.818912 -0.713998  2.069792   \n",
      "2 -0.325074  0.652118 -0.591299  ... -0.131520 -0.092517  2.155567  1.633889   \n",
      "3 -0.116118  0.030463  0.036004  ... -0.927029 -0.118557  1.781276  2.451208   \n",
      "4 -0.877318  0.227814 -1.035001  ...  0.067357  1.469933  1.834746  1.306961   \n",
      "\n",
      "        DWS        WS     WS/48       BPM      VORP     Dist.  \n",
      "0  0.631318  1.065467 -0.122276 -0.060994  0.344095  0.123069  \n",
      "1  2.516624  2.445925  0.993562  1.112235  2.166263 -0.614349  \n",
      "2  2.516624  2.130392  0.763310  1.645520  2.925501  0.600222  \n",
      "3 -1.149248  1.341559  0.249670  0.258978  0.723713  0.448400  \n",
      "4  3.040320  2.090950  0.816445  1.645520  2.773653  0.686977  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Cleaned and scaled data for clustering saved.\n",
      "Player info saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/gvzx8lwx3xd08y47f2s1y2rc0000gn/T/ipykernel_35224/3362484554.py:171: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(0, inplace=True)\n",
      "/var/folders/_8/gvzx8lwx3xd08y47f2s1y2rc0000gn/T/ipykernel_35224/3362484554.py:179: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna('Unknown', inplace=True) # Example: fill with 'Unknown' for categorical 'Pos' if needed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler # Added for scaling later\n",
    "\n",
    "# Define file paths for your CSVs\n",
    "per_100_poss_file = '../data/raw/NBA24-25PER100STATS.csv'\n",
    "advanced_stats_file = '../data/raw/NBA24-25ADVANCEDSTATS.csv'\n",
    "shooting_stats_file = '../data/raw/NBA24-25SHOOTINGSTATS.csv'\n",
    "\n",
    "# Load each CSV into a Pandas DataFrame (no skiprows needed for clean files)\n",
    "try:\n",
    "    df_per_100 = pd.read_csv(per_100_poss_file)\n",
    "    df_advanced = pd.read_csv(advanced_stats_file)\n",
    "    df_shooting = pd.read_csv(shooting_stats_file)\n",
    "\n",
    "    print(\"DataFrames loaded successfully. Head of each:\")\n",
    "    print(\"\\nPer 100 Possessions:\")\n",
    "    print(df_per_100.head())\n",
    "    print(\"\\nAdvanced Stats:\")\n",
    "    print(df_advanced.head())\n",
    "    print(\"\\nShooting Stats:\")\n",
    "    print(df_shooting.head())\n",
    "\n",
    "    # Let's check the actual column names\n",
    "    print(\"\\n=== COLUMN NAMES ===\")\n",
    "    print(\"Per 100 Possessions columns:\")\n",
    "    print(df_per_100.columns.tolist())\n",
    "    print(\"\\nAdvanced Stats columns:\")\n",
    "    print(df_advanced.columns.tolist())\n",
    "    print(\"\\nShooting Stats columns:\")\n",
    "    print(df_shooting.columns.tolist())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: One of the CSV files not found. Please ensure they are in the correct directory.\")\n",
    "    print(f\"Missing file: {e.filename}\")\n",
    "    exit() # Exit if essential files are missing\n",
    "\n",
    "# Check if the required columns exist in each DataFrame\n",
    "required_columns = ['Player', 'Team', 'Age'] # Note: Using 'Player', 'Team' (capitalized as per your data)\n",
    "for col in required_columns:\n",
    "    print(f\"\\nChecking column '{col}':\")\n",
    "    print(f\"  Per 100 Possessions: {'✓' if col in df_per_100.columns else '✗'}\")\n",
    "    print(f\"  Advanced Stats: {'✓' if col in df_advanced.columns else '✗'}\")\n",
    "    print(f\"  Shooting Stats: {'✓' if col in df_shooting.columns else '✗'}\")\n",
    "\n",
    "# Only proceed with data type conversion if columns exist\n",
    "if 'Age' in df_per_100.columns and 'Age' in df_advanced.columns and 'Age' in df_shooting.columns:\n",
    "    # Convert Age columns to the same type (float)\n",
    "    df_per_100['Age'] = df_per_100['Age'].astype(float)\n",
    "    df_advanced['Age'] = df_advanced['Age'].astype(float)\n",
    "    df_shooting['Age'] = df_shooting['Age'].astype(float)\n",
    "\n",
    "    print(\"\\n✓ Age columns converted to float\")\n",
    "else:\n",
    "    print(\"\\n✗ Age column missing in one or more DataFrames\")\n",
    "\n",
    "if 'Player' in df_per_100.columns and 'Player' in df_advanced.columns and 'Player' in df_shooting.columns:\n",
    "    # Also ensure Player and Team are strings\n",
    "    df_per_100['Player'] = df_per_100['Player'].astype(str)\n",
    "    df_advanced['Player'] = df_advanced['Player'].astype(str)\n",
    "    df_shooting['Player'] = df_shooting['Player'].astype(str)\n",
    "\n",
    "    print(\"✓ Player columns converted to string\")\n",
    "else:\n",
    "    print(\"✗ Player column missing in one or more DataFrames\")\n",
    "\n",
    "if 'Team' in df_per_100.columns and 'Team' in df_advanced.columns and 'Team' in df_shooting.columns:\n",
    "    df_per_100['Team'] = df_per_100['Team'].astype(str)\n",
    "    df_advanced['Team'] = df_advanced['Team'].astype(str)\n",
    "    df_shooting['Team'] = df_shooting['Team'].astype(str)\n",
    "\n",
    "    print(\"✓ Team columns converted to string\")\n",
    "else:\n",
    "    print(\"✗ Team column missing in one or more DataFrames\")\n",
    "\n",
    "\n",
    "# Check data types before merging\n",
    "print(\"\\n=== DATA TYPES BEFORE MERGING ===\")\n",
    "if 'Age' in df_per_100.columns:\n",
    "    print(\"Per 100 Possessions - Age:\", df_per_100['Age'].dtype)\n",
    "if 'Age' in df_advanced.columns:\n",
    "    print(\"Advanced Stats - Age:\", df_advanced['Age'].dtype)\n",
    "if 'Age' in df_shooting.columns:\n",
    "    print(\"Shooting Stats - Age:\", df_shooting['Age'].dtype)\n",
    "\n",
    "\n",
    "# Now we can merge using the correct column names\n",
    "# First merge: Per 100 Possessions and Advanced Stats\n",
    "if all(col in df_per_100.columns for col in ['Player', 'Team', 'Age']) and all(col in df_advanced.columns for col in ['Player', 'Team', 'Age']):\n",
    "    merged_df = pd.merge(df_per_100, df_advanced, on=['Player', 'Team', 'Age'], how='inner', suffixes=('_per100', '_adv'))\n",
    "    print(\"\\n✓ First merge completed successfully\")\n",
    "\n",
    "    # Second merge: Add Shooting Stats\n",
    "    if all(col in merged_df.columns for col in ['Player', 'Team', 'Age']) and all(col in df_shooting.columns for col in ['Player', 'Team', 'Age']):\n",
    "        final_df = pd.merge(merged_df, df_shooting, on=['Player', 'Team', 'Age'], how='inner', suffixes=('', '_shooting'))\n",
    "        print(\"✓ Second merge completed successfully\")\n",
    "\n",
    "        print(\"\\n--- Merged DataFrame Info ---\")\n",
    "        print(final_df.info())\n",
    "        print(\"\\nFinal Merged DataFrame Head:\")\n",
    "        print(final_df.head())\n",
    "\n",
    "        # --- NEW CODE BLOCKS START HERE ---\n",
    "\n",
    "        # --- Initial Data Cleaning and Feature Preparation ---\n",
    "\n",
    "        # 1. Handle redundant/duplicate columns from merging\n",
    "        # Identify columns that are duplicates from the suffixes but likely contain the same data\n",
    "        # Common duplicated columns might be 'Rk', 'G', 'GS', 'MP' etc.\n",
    "        # Check the columns of 'final_df' after the merge to identify actual duplicates.\n",
    "\n",
    "        columns_to_drop_after_merge = []\n",
    "        # Explicitly list some common ones to ensure they are handled, based on typical Basketball-Reference outputs\n",
    "        # and preferring the non-suffixed or '_per100' version if duplicates exist.\n",
    "        common_redundant_base_cols = ['Rk', 'G', 'GS', 'MP'] # Add more as you inspect final_df.columns if needed\n",
    "\n",
    "        for base_col in common_redundant_base_cols:\n",
    "            if f\"{base_col}_adv\" in final_df.columns and base_col in final_df.columns:\n",
    "                columns_to_drop_after_merge.append(f\"{base_col}_adv\")\n",
    "            if f\"{base_col}_shooting\" in final_df.columns and base_col in final_df.columns:\n",
    "                columns_to_drop_after_merge.append(f\"{base_col}_shooting\")\n",
    "            if f\"{base_col}_adv\" in final_df.columns and f\"{base_col}_per100\" in final_df.columns:\n",
    "                columns_to_drop_after_merge.append(f\"{base_col}_adv\")\n",
    "            if f\"{base_col}_shooting\" in final_df.columns and f\"{base_col}_per100\" in final_df.columns:\n",
    "                columns_to_drop_after_merge.append(f\"{base_col}_shooting\")\n",
    "\n",
    "        # You might have a 'Pos' column. If 'Pos' and 'Pos_adv' both exist, keep 'Pos'.\n",
    "        if 'Pos_adv' in final_df.columns and 'Pos' in final_df.columns:\n",
    "            columns_to_drop_after_merge.append('Pos_adv')\n",
    "\n",
    "\n",
    "        # Remove any duplicates from the list of columns to drop\n",
    "        columns_to_drop_after_merge = list(set(columns_to_drop_after_merge))\n",
    "\n",
    "        final_df.drop(columns=columns_to_drop_after_merge, inplace=True, errors='ignore')\n",
    "        print(f\"\\nDataFrame shape after dropping redundant columns: {final_df.shape}\")\n",
    "        print(\"Columns after dropping redundant ones:\")\n",
    "        print(final_df.columns.tolist())\n",
    "\n",
    "\n",
    "        # 2. Filter out players with insufficient playing time\n",
    "        min_mp_threshold = 500 # Example: Minimum 500 minutes played for a full season. Adjust if needed.\n",
    "\n",
    "        # Ensure 'MP' column exists after dropping duplicates.\n",
    "        # Based on Basketball-Reference, 'MP' (Minutes Played) is usually in the base Per Game/Per 100 table.\n",
    "        # If your 'MP' became 'MP_per100' and you dropped the original 'MP', adjust the name.\n",
    "        mp_col_name = 'MP' # Default expected column name\n",
    "        if 'MP_per100' in final_df.columns:\n",
    "            mp_col_name = 'MP_per100' # Use the suffixed one if that's what remained\n",
    "\n",
    "        if mp_col_name not in final_df.columns:\n",
    "            print(f\"Error: Could not find a suitable minutes played column ('MP' or 'MP_per100'). Please check your data.\")\n",
    "            exit()\n",
    "\n",
    "        final_df = final_df[final_df[mp_col_name] >= min_mp_threshold].copy()\n",
    "        print(f\"\\nFiltered to players with >= {min_mp_threshold} minutes. New shape: {final_df.shape}\")\n",
    "\n",
    "\n",
    "        # 3. Handling Missing Values (Imputation)\n",
    "        print(\"\\n--- Missing Value Check (before imputation) ---\")\n",
    "        # Only show columns with NaNs and their counts\n",
    "        nan_counts = final_df.isnull().sum()\n",
    "        print(nan_counts[nan_counts > 0])\n",
    "\n",
    "        # Impute missing numerical values in `final_df`\n",
    "        for col in final_df.columns:\n",
    "            if pd.api.types.is_numeric_dtype(final_df[col]): # Ensure it's a numeric column\n",
    "                if final_df[col].isnull().any():\n",
    "                    # Common imputation for percentages/ratios where NaN means 'no attempts' is 0\n",
    "                    # Common patterns for percentage/ratio columns that might be 0 for NaNs\n",
    "                    if any(s in col for s in ['%', 'Ar', 'Dist']) or col in ['PER', 'TS%', 'USG%', 'eFG%', 'FTAr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'BPM', 'VORP']: # Broaden this as needed based on your columns\n",
    "                        final_df[col].fillna(0, inplace=True)\n",
    "                    else:\n",
    "                        # For other numerical stats, median is often more robust to outliers than mean\n",
    "                        median_val = final_df[col].median()\n",
    "                        final_df[col].fillna(median_val, inplace=True)\n",
    "                        # print(f\"Imputed missing values in '{col}' with median: {median_val}\")\n",
    "            # Handle non-numeric NaNs if any (e.g., in 'Pos' if it's missing for some players, unlikely for NBA stats)\n",
    "            elif final_df[col].isnull().any():\n",
    "                final_df[col].fillna('Unknown', inplace=True) # Example: fill with 'Unknown' for categorical 'Pos' if needed\n",
    "\n",
    "        print(\"\\n--- Missing Value Check (after imputation) ---\")\n",
    "        nan_counts_after = final_df.isnull().sum()\n",
    "        print(nan_counts_after[nan_counts_after > 0]) # Should ideally be empty\n",
    "\n",
    "\n",
    "        # --- NEW BLOCK START: Save the merged and cleaned (unscaled) data ---\n",
    "        # This DataFrame is now ready for feature selection and scaling,\n",
    "        # but retains all original columns (except dropped duplicates) and unscaled values.\n",
    "        output_cleaned_file = '../data/processed/nba_2025_player_stats_merged_cleaned.csv' # Adjust path to be relative to notebook\n",
    "        final_df.to_csv(output_cleaned_file, index=False)\n",
    "        print(f\"\\nMerged and cleaned data (unscaled) saved to {output_cleaned_file}\")\n",
    "        # --- NEW BLOCK END ---\n",
    "\n",
    "\n",
    "        # 4. Select features for clustering\n",
    "        # This is where you define which columns will be used for K-Means.\n",
    "        # This list is your 'df_clustering' columns.\n",
    "        features_for_clustering = [\n",
    "            # Per 100 Possessions (ensure column names match your final_df after merging)\n",
    "            # Use the exact column names after your merges and dropping redundant ones.\n",
    "            # Example: 'PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'PF'\n",
    "            # If your 'Pts' is 'PTS_per100', use that. Inspect your final_df.columns.\n",
    "            # Common Basketball-Reference columns after merges often become:\n",
    "            'PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'PF',\n",
    "            'FG%', '3P%', '2P%', 'FT%', # These might be just 'FG%', '3P%', 'FT%'\n",
    "            'eFG%', 'TS%', # These are typically from advanced stats\n",
    "            '3PAr', 'FTr', # Advanced stats\n",
    "            'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', # Advanced stats percentages\n",
    "            'OWS', 'DWS', 'WS', 'WS/48', 'BPM', 'VORP', # Advanced stats impact metrics\n",
    "            # Shooting Stats (ensure column names match)\n",
    "            'Dist.', # Average Shot Distance\n",
    "            '2P_FG%', '0-3_FG%', '3-10_FG%', '10-16_FG%', '16-3P_FG%', # FG% by distance\n",
    "            # You might also find 'Att_3P', 'Att_2P' etc. if they were kept\n",
    "            # Add or remove based on the actual columns in your final_df and your clustering goals.\n",
    "        ]\n",
    "\n",
    "        # Dynamically check and refine features_for_clustering based on available columns\n",
    "        actual_features = [col for col in features_for_clustering if col in final_df.columns]\n",
    "        missing_features = [col for col in features_for_clustering if col not in final_df.columns]\n",
    "\n",
    "        if missing_features:\n",
    "            print(f\"\\nWarning: The following desired features are missing and will be excluded from clustering: {missing_features}\")\n",
    "            print(\"Please check your original CSVs and merge process if these are critical.\")\n",
    "\n",
    "        df_clustering = final_df[actual_features].copy() # This will be the input to scaling\n",
    "\n",
    "        # Create player_info DataFrame (ensure all needed columns are present in final_df)\n",
    "        # This should happen *before* scaling df_clustering.\n",
    "        # Based on your prior error, 'PLAYER', 'TEAM', 'POS', 'AGE' might be 'Player', 'Team', 'Pos', 'Age'\n",
    "        # Adjust these column names to match what you actually have in final_df\n",
    "        player_info_cols = ['Player', 'Team', 'Pos', 'Age']\n",
    "        # Verify these exist in final_df\n",
    "        existing_player_info_cols = [col for col in player_info_cols if col in final_df.columns]\n",
    "        if len(existing_player_info_cols) < len(player_info_cols):\n",
    "            print(f\"Warning: Not all player info columns found. Missing: {list(set(player_info_cols) - set(existing_player_info_cols))}. Player info might be incomplete.\")\n",
    "        player_info = final_df[existing_player_info_cols].copy()\n",
    "\n",
    "\n",
    "        print(f\"\\nDataFrame for clustering created with shape: {df_clustering.shape}\")\n",
    "        print(\"Columns for clustering:\")\n",
    "        print(df_clustering.columns.tolist())\n",
    "\n",
    "\n",
    "        # 5. Feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(df_clustering)\n",
    "        df_scaled = pd.DataFrame(scaled_features, columns=df_clustering.columns)\n",
    "\n",
    "        print(\"\\n--- Scaled Features Head ---\")\n",
    "        print(df_scaled.head())\n",
    "\n",
    "\n",
    "        # 6. Save Processed Data for Clustering (scaled and player info)\n",
    "        df_scaled.to_csv('../data/processed/nba_2025_player_stats_scaled_for_clustering.csv', index=False)\n",
    "        player_info.to_csv('../data/processed/nba_2025_player_info.csv', index=False)\n",
    "        print(\"\\nCleaned and scaled data for clustering saved.\")\n",
    "        print(\"Player info saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"✗ Cannot perform second merge - missing required columns\")\n",
    "else:\n",
    "    print(\"✗ Cannot perform first merge - missing required columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301e4638-c1c5-4ddc-af7d-6ea6c22493de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered to players with >= 500 minutes. New shape: (436, 82)\n",
      "\n",
      "Warning: The following desired features are missing and will be excluded: ['2P_FG%', '0-3_FG%', '3-10_FG%', '10-16_FG%', '16-3P_FG%', 'Att_3P', 'Att_2P']\n",
      "\n",
      "DataFrame for clustering created with shape: (436, 30)\n",
      "Columns for clustering:\n",
      "['PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'PF', 'FG%', '3P%', '2P%', 'FT%', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'BPM', 'VORP', 'Dist.']\n"
     ]
    }
   ],
   "source": [
    "# --- Initial Data Cleaning and Feature Selection ---\n",
    "\n",
    "# First, let's make sure we have the merged DataFrame\n",
    "# If final_df is not defined, we need to run the previous cell first\n",
    "try:\n",
    "    final_df\n",
    "except NameError:\n",
    "    print(\"Error: final_df is not defined. Please run the previous cell first to load and merge the data.\")\n",
    "    print(\"Make sure to run the cells in order: 1) Load and merge data, 2) Clean and prepare data\")\n",
    "    exit()\n",
    "\n",
    "# 1. Handle redundant/duplicate columns from merging\n",
    "# Identify columns that are duplicates (e.g., 'MP_per100', 'MP_adv', 'G_per100', 'G_adv', etc.)\n",
    "# It's good practice to inspect `final_df.columns` to see what you have.\n",
    "\n",
    "# Example: Drop redundant minute played columns, keeping one (e.g., from per_100_poss)\n",
    "columns_to_drop_after_merge = []\n",
    "for col in final_df.columns:\n",
    "    if col.endswith('_adv') or col.endswith('_shooting') and col not in ['Player', 'Team', 'Age']: # Updated column names\n",
    "        original_col_name = col.replace('_adv', '').replace('_shooting', '')\n",
    "        if original_col_name in final_df.columns and original_col_name != col: # Check if original (un-suffixed) exists\n",
    "            # We assume the first column (from df_per_100) is the one to keep, drop the others\n",
    "            columns_to_drop_after_merge.append(col)\n",
    "        elif original_col_name + '_per100' in final_df.columns and original_col_name != col:\n",
    "             # If a column like 'MP' from advanced stats is now 'MP_adv' and 'MP_per100' exists, drop 'MP_adv'\n",
    "            columns_to_drop_after_merge.append(col)\n",
    "\n",
    "\n",
    "# Common columns that often exist in multiple tables but you only need one version:\n",
    "common_stats = ['G', 'GS', 'MP'] # Games, Games Started, Minutes Played\n",
    "\n",
    "for stat in common_stats:\n",
    "    if f\"{stat}_adv\" in final_df.columns and f\"{stat}_per100\" in final_df.columns:\n",
    "        columns_to_drop_after_merge.append(f\"{stat}_adv\") # Keep the per100 version\n",
    "    elif f\"{stat}_shooting\" in final_df.columns and f\"{stat}_per100\" in final_df.columns:\n",
    "         columns_to_drop_after_merge.append(f\"{stat}_shooting\") # Keep the per100 version\n",
    "\n",
    "\n",
    "final_df.drop(columns=columns_to_drop_after_merge, inplace=True, errors='ignore') # Use errors='ignore' in case some aren't present\n",
    "\n",
    "\n",
    "# 2. Filter out players with insufficient playing time\n",
    "# This is crucial for meaningful archetypes. For a full season, 500-700 minutes is a good lower bound.\n",
    "# Rookies might have less, so consider your minimum. A common threshold is 15-20 games OR 300-500 minutes.\n",
    "min_mp_threshold = 500 # Example: Minimum 500 minutes played\n",
    "final_df = final_df[final_df['MP'] >= min_mp_threshold].copy() # .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "print(f\"\\nFiltered to players with >= {min_mp_threshold} minutes. New shape: {final_df.shape}\")\n",
    "\n",
    "# 3. Select features for clustering\n",
    "# This is where your basketball knowledge comes in!\n",
    "# Aim for a diverse set of stats that capture different aspects of play.\n",
    "# Avoid highly correlated features initially to prevent redundancy (though PCA can handle this later).\n",
    "\n",
    "# Example feature selection (you'll refine this extensively!)\n",
    "features_for_clustering = [\n",
    "    # Per 100 Possessions (rate stats are generally best for clustering)\n",
    "    'PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'PF', # Basic volume stats\n",
    "    'FG%', '3P%', '2P%', 'FT%', # Shooting efficiency\n",
    "    # Advanced Stats\n",
    "    'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%',\n",
    "    'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'BPM', 'VORP',\n",
    "    # Shooting Stats (some might be redundant with advanced stats, choose carefully)\n",
    "    'Dist.', # Average Shot Distance\n",
    "    '2P_FG%', '0-3_FG%', '3-10_FG%', '10-16_FG%', '16-3P_FG%', # FG% by distance\n",
    "    'Att_3P', 'Att_2P', # Shot attempts (might already be covered by USG% but can be useful)\n",
    "]\n",
    "\n",
    "# Ensure all selected features exist in your final DataFrame\n",
    "# It's common to find some columns might not exist if they were merged with suffixes\n",
    "# or were only present in one of the original CSVs.\n",
    "# Remove any features from your list that aren't in final_df.columns\n",
    "actual_features = [col for col in features_for_clustering if col in final_df.columns]\n",
    "missing_features = [col for col in features_for_clustering if col not in final_df.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"\\nWarning: The following desired features are missing and will be excluded: {missing_features}\")\n",
    "\n",
    "df_clustering = final_df[actual_features].copy()\n",
    "\n",
    "# Add Player and Team for later interpretation (but exclude from clustering features)\n",
    "player_info = final_df[['Player', 'Team', 'Pos', 'Age']].copy() # Updated column names\n",
    "\n",
    "print(f\"\\nDataFrame for clustering created with shape: {df_clustering.shape}\")\n",
    "print(\"Columns for clustering:\")\n",
    "print(df_clustering.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284bebbb-a27e-418b-aed3-90350c356555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Value Check (before imputation) ---\n",
      "PTS      0\n",
      "AST      0\n",
      "TRB      0\n",
      "STL      0\n",
      "BLK      0\n",
      "TOV      0\n",
      "PF       0\n",
      "FG%      0\n",
      "3P%      0\n",
      "2P%      0\n",
      "FT%      0\n",
      "PER      0\n",
      "TS%      0\n",
      "3PAr     0\n",
      "FTr      0\n",
      "ORB%     0\n",
      "DRB%     0\n",
      "TRB%     0\n",
      "AST%     0\n",
      "STL%     0\n",
      "BLK%     0\n",
      "TOV%     0\n",
      "USG%     0\n",
      "OWS      0\n",
      "DWS      0\n",
      "WS       0\n",
      "WS/48    0\n",
      "BPM      0\n",
      "VORP     0\n",
      "Dist.    0\n",
      "dtype: int64\n",
      "\n",
      "--- Missing Value Check (after imputation) ---\n",
      "PTS      0\n",
      "AST      0\n",
      "TRB      0\n",
      "STL      0\n",
      "BLK      0\n",
      "TOV      0\n",
      "PF       0\n",
      "FG%      0\n",
      "3P%      0\n",
      "2P%      0\n",
      "FT%      0\n",
      "PER      0\n",
      "TS%      0\n",
      "3PAr     0\n",
      "FTr      0\n",
      "ORB%     0\n",
      "DRB%     0\n",
      "TRB%     0\n",
      "AST%     0\n",
      "STL%     0\n",
      "BLK%     0\n",
      "TOV%     0\n",
      "USG%     0\n",
      "OWS      0\n",
      "DWS      0\n",
      "WS       0\n",
      "WS/48    0\n",
      "BPM      0\n",
      "VORP     0\n",
      "Dist.    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Handle Missing Values ---\n",
    "print(\"\\n--- Missing Value Check (before imputation) ---\")\n",
    "print(df_clustering.isnull().sum())\n",
    "\n",
    "# Strategy: Impute missing numerical values.\n",
    "# For percentages/ratios: often 0 makes sense if it's truly a \"no attempts\" scenario.\n",
    "# For other stats: mean or median imputation can be used.\n",
    "# A robust approach is to check each column individually.\n",
    "\n",
    "for col in df_clustering.columns:\n",
    "    if df_clustering[col].isnull().any():\n",
    "        # A common imputation for stats where NaN means 'no attempts' is 0\n",
    "        if 'FG%' in col or '3P%' in col or 'FT%' in col or 'Ar' in col or 'Dist' in col: # Check for percentage/attempt ratio columns\n",
    "            df_clustering[col].fillna(0, inplace=True)\n",
    "        else:\n",
    "            # For other numerical stats, median is often more robust to outliers than mean\n",
    "            median_val = df_clustering[col].median()\n",
    "            df_clustering[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Imputed missing values in '{col}' with median: {median_val}\")\n",
    "\n",
    "print(\"\\n--- Missing Value Check (after imputation) ---\")\n",
    "print(df_clustering.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f080de3e-a5b0-4649-99b7-4462d3d43fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scaled Features Head ---\n",
      "        PTS       AST       TRB       STL       BLK       TOV        PF  \\\n",
      "0  0.219874 -0.103204 -1.177485 -0.811858 -0.359945 -0.458698 -1.571965   \n",
      "1 -0.603001  0.944976  0.917143  0.589310 -0.614092 -0.001050 -0.423486   \n",
      "2  2.247671  0.346016 -0.304723 -0.111274 -0.105797  1.463427 -1.130242   \n",
      "3  1.748069  1.543936 -0.878252 -0.811858 -0.868239  1.097307 -0.335142   \n",
      "4  1.424797  2.554680 -0.204979  0.764456  0.021276  3.019432 -0.865209   \n",
      "\n",
      "        FG%       3P%       2P%  ...      BLK%      TOV%      USG%       OWS  \\\n",
      "0  0.465977  0.247549  0.831608  ... -0.396690 -0.691456  0.052407  1.143497   \n",
      "1  0.839114  0.040330  1.198810  ... -0.661859  0.818912 -0.713998  2.069792   \n",
      "2 -0.325074  0.652118 -0.591299  ... -0.131520 -0.092517  2.155567  1.633889   \n",
      "3 -0.116118  0.030463  0.036004  ... -0.927029 -0.118557  1.781276  2.451208   \n",
      "4 -0.877318  0.227814 -1.035001  ...  0.067357  1.469933  1.834746  1.306961   \n",
      "\n",
      "        DWS        WS     WS/48       BPM      VORP     Dist.  \n",
      "0  0.631318  1.065467 -0.122276 -0.060994  0.344095  0.123069  \n",
      "1  2.516624  2.445925  0.993562  1.112235  2.166263 -0.614349  \n",
      "2  2.516624  2.130392  0.763310  1.645520  2.925501  0.600222  \n",
      "3 -1.149248  1.341559  0.249670  0.258978  0.723713  0.448400  \n",
      "4  3.040320  2.090950  0.816445  1.645520  2.773653  0.686977  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Feature Scaling ---\n",
    "# StandardScaler (Z-score normalization) is generally preferred for K-Means.\n",
    "# It transforms data to have a mean of 0 and a standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_clustering)\n",
    "\n",
    "# Convert back to a DataFrame for easier handling, keeping column names\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df_clustering.columns)\n",
    "\n",
    "print(\"\\n--- Scaled Features Head ---\")\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e4dbf3-7912-400f-9ff3-516298d85f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned and scaled data saved as 'nba_2025_player_stats_scaled_for_clustering.csv'\n",
      "Player info saved as 'nba_2025_player_info.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned and scaled data for clustering\n",
    "df_scaled.to_csv('../data/raw/nba_2025_player_stats_scaled_for_clustering.csv', index=False)\n",
    "player_info.to_csv('../data/raw/nba_2025_player_info.csv', index=False) # Keep player info separate\n",
    "print(\"\\nCleaned and scaled data saved as 'nba_2025_player_stats_scaled_for_clustering.csv'\")\n",
    "print(\"Player info saved as 'nba_2025_player_info.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2bd83-dd67-4547-af8c-31cfb7781967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
